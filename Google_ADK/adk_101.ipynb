{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d86c47cb",
   "metadata": {},
   "source": [
    "#### What is ADK?\n",
    "\n",
    "As a reminder, ADK is a Python framework designed to streamline the development of applications powered by Large Language Models (LLMs). It offers robust building blocks for creating agents that can reason, plan, utilize tools, interact dynamically with users, and collaborate effectively within a team.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025c7212",
   "metadata": {},
   "source": [
    "\n",
    "In this tutorial, we will master:\n",
    "\n",
    "✅ Tool Definition & Usage: Crafting Python functions (tools) that grant agents specific abilities (like fetching data) and instructing agents on how to use them effectively. </br>\n",
    "✅ Multi-LLM Flexibility: Configuring agents to utilize various leading LLMs (Gemini, GPT-4o, Claude Sonnet) via LiteLLM integration, allowing you to choose the best model for each task. </br>\n",
    "✅ Agent Delegation & Collaboration: Designing specialized sub-agents and enabling automatic routing (auto flow) of user requests to the most appropriate agent within a team.</br>\n",
    "✅ Session State for Memory: Utilizing Session State and ToolContext to enable agents to remember information across conversational turns, leading to more contextual interactions. </br>\n",
    "✅ Safety Guardrails with Callbacks: Implementing before_model_callback and before_tool_callback to inspect, modify, or block requests/tool usage based on predefined rules, enhancing application safety and control.</br>\n",
    "\n",
    "End State Expectation: </br>\n",
    "\n",
    "By completing this tutorial, you will have built a functional multi-agent Weather Bot system. This system will not only provide weather information but also handle conversational niceties, remember the last city checked, and operate within defined safety boundaries, all orchestrated using ADK. </br>\n",
    "\n",
    "Prerequisites: </br>\n",
    "\n",
    "✅ Solid understanding of Python programming. </br>\n",
    "✅ Familiarity with Large Language Models (LLMs), APIs, and the concept of agents. </br>\n",
    "❗ Crucially: Completion of the ADK Quickstart tutorial(s) or equivalent foundational knowledge of ADK basics (Agent, Runner, SessionService, basic Tool usage). This tutorial builds directly upon those concepts. </br>\n",
    "✅ API Keys for the LLMs you intend to use (e.g., Google AI Studio for Gemini, OpenAI Platform, Anthropic Console)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9274850e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff0e73e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # @title Step 0: Setup and Installation\n",
    "# # Install ADK and LiteLLM for multi-model support\n",
    "\n",
    "# !pip install google-adk -q\n",
    "# !pip install litellm -q\n",
    "\n",
    "# print(\"Installation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5aeadc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries Imported\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "import asyncio\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.models.lite_llm import LiteLlm\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.runners import Runner\n",
    "from google.genai import types # For creating messages Content/parts\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import logging \n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "print(\"Libraries Imported\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f38d0f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Environment configured.\n"
     ]
    }
   ],
   "source": [
    "# --- Define Model Constants for easier use ---\n",
    "\n",
    "MODEL_GEMINI_2_0_FLASH = \"gemini-2.0-flash\"\n",
    "MODEL_GEMMA=\"gemma3:27b\"\n",
    "\n",
    "# Note: Specific model names might change. Refer to LiteLLM/Provider documentation.\n",
    "MODEL_GPT_4O = \"openai/gpt-4o\"\n",
    "MODEL_CLAUDE_SONNET = \"anthropic/claude-3-sonnet-20240229\"\n",
    "\n",
    "\n",
    "print(\"\\nEnvironment configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587ad217",
   "metadata": {},
   "source": [
    "## 1. First Agent - Weather Lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6373aca8",
   "metadata": {},
   "source": [
    "Let's begin by building the fundamental component of our Weather Bot: a single agent capable of performing a specific task – looking up weather information. This involves creating two core pieces:\n",
    "\n",
    "- **A Tool:** A Python function that equips the agent with the ability to fetch weather data.\n",
    "- **An Agent:** The AI \"brain\" that understands the user's request, knows it has a weather tool, and decides when and how to use it.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed7c203",
   "metadata": {},
   "source": [
    "### 1.1 Define the Tool (get_weather)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76ded07",
   "metadata": {},
   "source": [
    "In ADK, Tools are the building blocks that give agents concrete capabilities beyond just text generation. They are typically regular Python functions that perform specific actions, like calling an API, querying a database, or performing calculations.\n",
    "\n",
    "Our first tool will provide a mock weather report. This allows us to focus on the agent structure without needing external API keys yet. Later, you could easily swap this mock function with one that calls a real weather service.\n",
    "\n",
    "**Key Concept:** **Docstrings are Crucial!** The agent's LLM relies heavily on the function's docstring to understand:\n",
    "\n",
    "What the tool does.\n",
    "When to use it.\n",
    "What arguments it requires (city: str).\n",
    "What information it returns.\n",
    "Best Practice: Write clear, descriptive, and accurate docstrings for your tools. This is essential for the LLM to use the tool correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "492ce386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tool: get_weather called for city: New York ---\n",
      "{'status': 'success', 'report': 'The weather in New York is sunny with a temperature of 25°C.'}\n",
      "--- Tool: get_weather called for city: Paris ---\n",
      "{'status': 'error', 'error_message': \"Sorry, I don't have weather information for 'Paris'.\"}\n"
     ]
    }
   ],
   "source": [
    "# @title Define the get_weather Tool\n",
    "def get_weather(city: str) -> dict:\n",
    "    \"\"\"Retrieves the current weather report for a specified city.\n",
    "\n",
    "    Args:\n",
    "        city (str): The name of the city (e.g., \"New York\", \"London\", \"Tokyo\").\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the weather information.\n",
    "              Includes a 'status' key ('success' or 'error').\n",
    "              If 'success', includes a 'report' key with weather details.\n",
    "              If 'error', includes an 'error_message' key.\n",
    "    \"\"\"\n",
    "    print(f\"--- Tool: get_weather called for city: {city} ---\") # Log tool execution\n",
    "    city_normalized = city.lower().replace(\" \", \"\") # Basic normalization\n",
    "\n",
    "     # Mock weather data\n",
    "    mock_weather_db = {\n",
    "        \"newyork\": {\"status\": \"success\", \"report\": \"The weather in New York is sunny with a temperature of 25°C.\"},\n",
    "        \"london\": {\"status\": \"success\", \"report\": \"It's cloudy in London with a temperature of 15°C.\"},\n",
    "        \"tokyo\": {\"status\": \"success\", \"report\": \"Tokyo is experiencing light rain and a temperature of 18°C.\"},\n",
    "    }\n",
    "\n",
    "    if city_normalized in mock_weather_db:\n",
    "        return mock_weather_db[city_normalized]\n",
    "    else:\n",
    "        return {\"status\": \"error\", \"error_message\": f\"Sorry, I don't have weather information for '{city}'.\"}\n",
    "\n",
    "# Example tool usage (optional test)\n",
    "print(get_weather(\"New York\"))\n",
    "print(get_weather(\"Paris\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d279517",
   "metadata": {},
   "source": [
    "### 1.2 Define the Agent (weather_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652d8c2b",
   "metadata": {},
   "source": [
    "Now, let's create the Agent itself. \n",
    "\n",
    "We configure it with several key parameters:\n",
    "\n",
    "- `name:` A unique identifier for this agent (e.g., \"weather_agent_v1\").\n",
    "model: Specifies which LLM to use (e.g., MODEL_GEMINI_2_0_FLASH). We'll start with a specific Gemini model.\n",
    "- `description:` A concise summary of the agent's overall purpose. This becomes crucial later when other agents need to decide whether to delegate tasks to this agent.\n",
    "- `instruction:` Detailed guidance for the LLM on how to behave, its persona, its goals, and specifically how and when to utilize its assigned tools.\n",
    "- `tools:` A list containing the actual Python tool functions the agent is allowed to use (e.g., [get_weather]).\n",
    "\n",
    "**Best Practice:** Provide clear and specific instruction prompts. The more detailed the instructions, the better the LLM can understand its role and how to use its tools effectively. Be explicit about error handling if needed.\n",
    "\n",
    "**Best Practice:** Choose descriptive name and description values. These are used internally by ADK and are vital for features like automatic delegation (covered later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc730ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 'weather_agent_v1' created using model 'gemini-2.0-flash'.\n"
     ]
    }
   ],
   "source": [
    "# @title Define the Weather Agent\n",
    "# Use one of the model constants defined earlier\n",
    "AGENT_MODEL = MODEL_GEMINI_2_0_FLASH # Starting with Gemini\n",
    "\n",
    "weather_agent = Agent(name=\"weather_agent_v1\",\n",
    "                      model=AGENT_MODEL,\n",
    "                      description=\"Provides weather information for specific cities\",\n",
    "                      instruction=\"You are a helpful weather assistant. \"\n",
    "                \"When the user asks for the weather in a specific city, \"\n",
    "                \"use the 'get_weather' tool to find the information. \"\n",
    "                \"If the tool returns an error, inform the user politely. \"\n",
    "                \"If the tool is successful, present the weather report clearly.\",\n",
    "                tools=[get_weather], # Pass the function directly\n",
    "                )\n",
    "print(f\"Agent '{weather_agent.name}' created using model '{AGENT_MODEL}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2540df",
   "metadata": {},
   "source": [
    "### 1.3 Setup Runner and Session Service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400c1487",
   "metadata": {},
   "source": [
    "To manage conversations and execute the agent, we need two more components:\n",
    "\n",
    "- `SessionService:` Responsible for managing conversation history and state for different users and sessions. The `InMemorySessionService` is a simple implementation that stores everything in memory, suitable for testing and simple applications. It keeps track of the messages exchanged. We'll explore state persistence more in Step 4. </br>\n",
    "\n",
    "\n",
    "- `Runner:` The engine that orchestrates the interaction flow. It takes user input, routes it to the appropriate agent, manages calls to the LLM and tools based on the agent's logic, handles session updates via the `SessionService`, and yields events representing the progress of the interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53c56b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session created: App='weather_tutorial_app', User='user_1', Session='session_001'\n",
      "Runner created for agent 'weather_agent_v1'.\n"
     ]
    }
   ],
   "source": [
    "# @title Setup Session Service and Runner\n",
    "# --- Session Management ---\n",
    "# Key Concept: SessionService stores conversation history & state.\n",
    "# InMemorySessionService is simple, non-persistent storage for this tutorial.\n",
    "session_service = InMemorySessionService()\n",
    "\n",
    "# Define constants for identifying the interaction context\n",
    "APP_NAME = \"weather_tutorial_app\"\n",
    "USER_ID = \"user_1\"\n",
    "SESSION_ID = \"session_001\" # Using a fixed ID for simplicity\n",
    "\n",
    "# Create the specific session where the conversation will happen\n",
    "session = session_service.create_session(\n",
    "    app_name=APP_NAME,\n",
    "    user_id=USER_ID,\n",
    "    session_id=SESSION_ID\n",
    ")\n",
    "print(f\"Session created: App='{APP_NAME}', User='{USER_ID}', Session='{SESSION_ID}'\")\n",
    "\n",
    "\n",
    "# --- Runner ---\n",
    "# Key Concept: Runner orchestrates the agent execution loop.\n",
    "runner = Runner(\n",
    "    agent=weather_agent, # The agent we want to run\n",
    "    app_name=APP_NAME,   # Associates runs with our app\n",
    "    session_service=session_service # Uses our session manager\n",
    ")\n",
    "print(f\"Runner created for agent '{runner.agent.name}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dc83a7",
   "metadata": {},
   "source": [
    "### 1.4 Interact with the Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa393ea",
   "metadata": {},
   "source": [
    "We need a way to send messages to out agent and receive its responses. Since LLM calls and tool executions can take time, ADK's `Runner` operates asynchronously.\n",
    "\n",
    "We'll define an `async` helper function (`call_agent_async`) that:\n",
    "1. Takes a user query string.\n",
    "2. Packages it into the ADK 'Content' format.\n",
    "3. Calls 'runner.run_async' , providing the user/session context and the new message.\n",
    "4. Iterates through the **Events** yielded by runner. Events represent steps in the agents execution( e.g tool call requested, tool result received, intermediate LLM thought, final response.)\n",
    "5. Identifies and prints the final reponse event using `event.is_final_reponse()`\n",
    "\n",
    "**Why async??**\n",
    "\n",
    "Interactions with LLMs and potentially tools (like external APIs) are I/O-bound operations. Using `asyncio` allows the program to handle these operations efficiently without blocking execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d204a119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Define Agent Interaction Function\n",
    "\n",
    "from google.genai import types # For creating message Content/Parts\n",
    "\n",
    "async def call_agent_async(query: str, runner, user_id, session_id):\n",
    "    \"\"\"Sends a query to the agent and prints the final response.\"\"\"\n",
    "\n",
    "    print(f\"\\n>>> User Query: {query}\")\n",
    "    # Prepare the user's message in ADK format\n",
    "    content = types.Content(role='user', parts=[types.Part(text=query)])\n",
    "\n",
    "    final_response_text = \"Agent did not produce a final response.\" # Default\n",
    "    \n",
    "    # Key Concept: run_async executes the agent logic and yields Events.\n",
    "    # We iterate through events to find the final answer.\n",
    "    async for event in runner.run_async(user_id=user_id, session_id=session_id, new_message=content):\n",
    "        # You can uncomment the line below to see *all* events during execution\n",
    "        # print(f\"  [Event] Author: {event.author}, Type: {type(event).__name__}, Final: {event.is_final_response()}, Content: {event.content}\")\n",
    "        # Key Concept: is_final_response() marks the concluding message for the turn.\n",
    "        if event.is_final_response():\n",
    "            if event.content and event.content.parts:\n",
    "                # Assuming text response in the first part\n",
    "                final_response_text = event.content.parts[0].text\n",
    "            elif event.actions and event.actions.escalate: # Handle potential errors/escalations\n",
    "                final_response_text = f\"Agent escalated: {event.error_message or 'No specific message.'}\"\n",
    "            # Add more checks here if needed (e.g., specific error codes)\n",
    "            break # Stop processing events once the final response is found\n",
    "\n",
    "    print(f\"<<< Agent Response: {final_response_text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6422f9a",
   "metadata": {},
   "source": [
    "### 1.5 Run the Conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a100afa1",
   "metadata": {},
   "source": [
    "Finally, let's test our setup by sending a few queries to the agent. We wrap our async calls in a main `async` function and run it using `await`.\n",
    "\n",
    "Watch the output:\n",
    "\n",
    "- See the user queries.\n",
    "- Notice the `--- Tool: get_weather called... ---` logs when the agent uses the tool.\n",
    "- Observe the agent's final responses, including how it handles the case where weather data isn't available (for Paris)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f155dcd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> User Query: What is the weather like in London?\n",
      "\n",
      "--- Tool: get_weather called for city: London ---\n",
      "<<< Agent Response: The weather in London is cloudy with a temperature of 15°C.\n",
      "\n",
      "\n",
      ">>> User Query: How about Paris?\n",
      "--- Tool: get_weather called for city: Paris ---\n",
      "<<< Agent Response: I am sorry, I don't have weather information for Paris.\n",
      "\n",
      "\n",
      ">>> User Query: Tell me the weather in New York\n",
      "--- Tool: get_weather called for city: New York ---\n",
      "<<< Agent Response: The weather in New York is sunny with a temperature of 25°C.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Run the Initial Conversation\n",
    "\n",
    "# We need an async function to await our interaction helper\n",
    "async def run_conversation():\n",
    "    await call_agent_async(\"What is the weather like in London?\",\n",
    "                                       runner=runner,\n",
    "                                       user_id=USER_ID,\n",
    "                                       session_id=SESSION_ID)\n",
    "\n",
    "    await call_agent_async(\"How about Paris?\",\n",
    "                                       runner=runner,\n",
    "                                       user_id=USER_ID,\n",
    "                                       session_id=SESSION_ID) # Expecting the tool's error message\n",
    "\n",
    "    await call_agent_async(\"Tell me the weather in New York\",\n",
    "                                       runner=runner,\n",
    "                                       user_id=USER_ID,\n",
    "                                       session_id=SESSION_ID)\n",
    "\n",
    "# Execute the conversation using await in an async context (like Colab/Jupyter)\n",
    "await run_conversation()\n",
    "\n",
    "# --- OR ---\n",
    "\n",
    "# Uncomment the following lines if running as a standard Python script (.py file):\n",
    "# import asyncio\n",
    "# if __name__ == \"__main__\":\n",
    "#     try:\n",
    "#         asyncio.run(run_conversation())\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e24939",
   "metadata": {},
   "source": [
    "## 2. Going Multi-Model with LiteLLM [Optional]\n",
    "\n",
    "ADK makes switching between models seamless through its integration with the `LiteLLM` library. LiteLLM acts as a consistent interface to over 100 different LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52448e5d",
   "metadata": {},
   "source": [
    "#### 2.1 Import LiteLlm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d64018",
   "metadata": {},
   "source": [
    "```python\n",
    "#@title 1. Import LiteLlm\n",
    "from google.adk.models.lite_llm import LiteLlm\n",
    "```\n",
    "\n",
    "Key Concept: LiteLlm Wrapper: The LiteLlm(model=\"provider/model_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8f1f955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 1. Import LiteLlm\n",
    "from google.adk.models.lite_llm import LiteLlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b40f6d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 'weather_agent_gpt' created using model 'openai/gpt-4o'.\n",
      "Session created: App='weather_tutorial_app_gpt', User='user_1_gpt', Session='session_001_gpt'\n",
      "Runner created for agent 'weather_agent_gpt'.\n",
      "\n",
      "--- Testing GPT Agent ---\n",
      "\n",
      ">>> User Query: What's the weather in Tokyo?\n",
      "--- Tool: get_weather called for city: Tokyo ---\n",
      "<<< Agent Response: OK. The weather in Tokyo is light rain and the temperature is 18°C.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Define and Test GPT Agent\n",
    "\n",
    "# Make sure 'get_weather' function from Step 1 is defined in your environment.\n",
    "# Make sure 'call_agent_async' is defined from earlier.\n",
    "\n",
    "# --- Agent using GPT-4o ---\n",
    "weather_agent_gpt = None # Initialize to None\n",
    "runner_gpt = None      # Initialize runner to None\n",
    "# MODEL_GPT_4O='google/gemma-3-27b-it'\n",
    "try:\n",
    "    weather_agent_gpt = Agent(\n",
    "        name=\"weather_agent_gpt\",\n",
    "        # Key change: Wrap the LiteLLM model identifier\n",
    "        model=LiteLlm(model='gemini/gemini-2.0-flash-001'),\n",
    "        description=\"Provides weather information (using GPT-4o).\",\n",
    "        instruction=\"You are a helpful weather assistant powered by GPT-4o. \"\n",
    "                    \"Use the 'get_weather' tool for city weather requests. \"\n",
    "                    \"Clearly present successful reports or polite error messages based on the tool's output status.\",\n",
    "        tools=[get_weather], # Re-use the same tool\n",
    "    )\n",
    "    print(f\"Agent '{weather_agent_gpt.name}' created using model '{MODEL_GPT_4O}'.\")\n",
    "\n",
    "    # InMemorySessionService is simple, non-persistent storage for this tutorial.\n",
    "    session_service_gpt = InMemorySessionService() # Create a dedicated service\n",
    "\n",
    "    # Define constants for identifying the interaction context\n",
    "    APP_NAME_GPT = \"weather_tutorial_app_gpt\" # Unique app name for this test\n",
    "    USER_ID_GPT = \"user_1_gpt\"\n",
    "    SESSION_ID_GPT = \"session_001_gpt\" # Using a fixed ID for simplicity\n",
    "\n",
    "    # Create the specific session where the conversation will happen\n",
    "    session_gpt = session_service_gpt.create_session(\n",
    "        app_name=APP_NAME_GPT,\n",
    "        user_id=USER_ID_GPT,\n",
    "        session_id=SESSION_ID_GPT\n",
    "    )\n",
    "    print(f\"Session created: App='{APP_NAME_GPT}', User='{USER_ID_GPT}', Session='{SESSION_ID_GPT}'\")\n",
    "\n",
    "    # Create a runner specific to this agent and its session service\n",
    "    runner_gpt = Runner(\n",
    "        agent=weather_agent_gpt,\n",
    "        app_name=APP_NAME_GPT,       # Use the specific app name\n",
    "        session_service=session_service_gpt # Use the specific session service\n",
    "        )\n",
    "    print(f\"Runner created for agent '{runner_gpt.agent.name}'.\")\n",
    "\n",
    "    # --- Test the GPT Agent ---\n",
    "    print(\"\\n--- Testing GPT Agent ---\")\n",
    "    # Ensure call_agent_async uses the correct runner, user_id, session_id\n",
    "    await call_agent_async(query = \"What's the weather in Tokyo?\",\n",
    "                           runner=runner_gpt,\n",
    "                           user_id=USER_ID_GPT,\n",
    "                           session_id=SESSION_ID_GPT)\n",
    "    # --- OR ---\n",
    "\n",
    "    # Uncomment the following lines if running as a standard Python script (.py file):\n",
    "    # import asyncio\n",
    "    # if __name__ == \"__main__\":\n",
    "    #     try:\n",
    "    #         asyncio.run(call_agent_async(query = \"What's the weather in Tokyo?\",\n",
    "    #                      runner=runner_gpt,\n",
    "    #                       user_id=USER_ID_GPT,\n",
    "    #                       session_id=SESSION_ID_GPT)\n",
    "    #     except Exception as e:\n",
    "    #         print(f\"An error occurred: {e}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Could not create or run GPT agent '{MODEL_GPT_4O}'. Check API Key and model name. Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d0ad2e",
   "metadata": {},
   "source": [
    "## 3. Building an Agent Team - Delegation for Greetings & Farewells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63de546f",
   "metadata": {},
   "source": [
    "In Steps 1 and 2, we built and experimented with a single agent focused solely on weather lookups. We could keep adding more tools and complex instructions to our single weather agent, but this can quickly become unmanageable and less efficient.\n",
    "\n",
    "A more robust approach is to build an **Agent Team**. </br>\n",
    "This involves: </br>\n",
    "\n",
    "1. Creating multiple, **specialized agents**, each designed for a specific capability (e.g., one for weather, one for greetings, one for calculations).\n",
    "2. Designating a **root agent** (or orchestrator) that receives the initial user request.\n",
    "3. Enabling the root agent to **delegate** the request to the most appropriate specialized sub-agent based on the user's intent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d243d8",
   "metadata": {},
   "source": [
    "**Why build an Agent Team?**\n",
    "\n",
    "- **Modularity:** Easier to develop, test, and maintain individual agents.\n",
    "- **Specialization:** Each agent can be fine-tuned (instructions, model choice) for its specific task.\n",
    "- **Scalability:** Simpler to add new capabilities by adding new agents.\n",
    "- **Efficiency:** Allows using potentially simpler/cheaper models for simpler tasks (like greetings)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992baa1d",
   "metadata": {},
   "source": [
    "In this step, we will:\n",
    "\n",
    "1. Define simple tools for handling greetings (say_hello) and farewells (say_goodbye).\n",
    "2. Create two new specialized sub-agents: greeting_agent and farewell_agent.\n",
    "3. Update our main weather agent (weather_agent_v2) to act as the root agent.\n",
    "4. Configure the root agent with its sub-agents, enabling automatic delegation.\n",
    "5. Test the delegation flow by sending different types of requests to the root agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331f5b79",
   "metadata": {},
   "source": [
    "### 3.1 Define Tools for Sub-Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f168fdc",
   "metadata": {},
   "source": [
    "First, let's create the simple Python functions that will serve as tools for our new specialist agents. Remember, clear docstrings are vital for the agents that will use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62a5032c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greeting and Farewell tools defined.\n",
      "--- Tool: say_hello called with name: Alice ---\n",
      "Hello, Alice!\n",
      "--- Tool: say_goodbye called ---\n",
      "Goodbye! Have a great day.\n"
     ]
    }
   ],
   "source": [
    "# @title Define Tools for Greeting and Farewell Agents\n",
    "\n",
    "# Ensure 'get_weather' from Step 1 is available if running this step independently.\n",
    "# def get_weather(city: str) -> dict: ... (from Step 1)\n",
    "\n",
    "def say_hello(name: str = \"there\") -> str:\n",
    "    \"\"\"Provides a simple greeting, optionally addressing the user by name.\n",
    "\n",
    "    Args:\n",
    "        name (str, optional): The name of the person to greet. Defaults to \"there\".\n",
    "\n",
    "    Returns:\n",
    "        str: A friendly greeting message.\n",
    "    \"\"\"\n",
    "    print(f\"--- Tool: say_hello called with name: {name} ---\")\n",
    "    return f\"Hello, {name}!\"\n",
    "\n",
    "def say_goodbye() -> str:\n",
    "    \"\"\"Provides a simple farewell message to conclude the conversation.\"\"\"\n",
    "    print(f\"--- Tool: say_goodbye called ---\")\n",
    "    return \"Goodbye! Have a great day.\"\n",
    "\n",
    "print(\"Greeting and Farewell tools defined.\")\n",
    "\n",
    "# Optional self-test\n",
    "print(say_hello(\"Alice\"))\n",
    "print(say_goodbye())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c07fb4",
   "metadata": {},
   "source": [
    "### 3.2 Define the Sub-Agents (Greeting & Farewell)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f6fb60",
   "metadata": {},
   "source": [
    "Now, create the Agent instances for our specialists. Notice their highly focused instruction and, critically, their clear description. The description is the primary information the root agent uses to decide when to delegate to these sub-agents.\n",
    "\n",
    "Best Practice: Sub-agent description fields should accurately and concisely summarize their specific capability. This is crucial for effective automatic delegation.\n",
    "\n",
    "Best Practice: Sub-agent instruction fields should be tailored to their limited scope, telling them exactly what to do and what not to do (e.g., \"Your only task is...\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "805085f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Agent 'greeting_agent' created using model 'gemini-2.0-flash'.\n",
      "✅ Agent 'farewell_agent' created using model 'gemini-2.0-flash'.\n"
     ]
    }
   ],
   "source": [
    "# @title Define Greeting and Farewell Sub-Agents\n",
    "\n",
    "# If you want to use models other than Gemini, Ensure LiteLlm is imported and API keys are set (from Step 0/2)\n",
    "# from google.adk.models.lite_llm import LiteLlm\n",
    "# MODEL_GPT_4O, MODEL_CLAUDE_SONNET etc. should be defined\n",
    "# Or else, continue to use: model = MODEL_GEMINI_2_0_FLASH\n",
    "\n",
    "# --- Greeting Agent ---\n",
    "greeting_agent = None\n",
    "try:\n",
    "    greeting_agent = Agent(\n",
    "        # Using a potentially different/cheaper model for a simple task\n",
    "        model = MODEL_GEMINI_2_0_FLASH,\n",
    "        # model=LiteLlm(model=MODEL_GPT_4O), # If you would like to experiment with other models\n",
    "        name=\"greeting_agent\",\n",
    "        instruction=\"You are the Greeting Agent. Your ONLY task is to provide a friendly greeting to the user. \"\n",
    "                    \"Use the 'say_hello' tool to generate the greeting. \"\n",
    "                    \"If the user provides their name, make sure to pass it to the tool. \"\n",
    "                    \"Do not engage in any other conversation or tasks.\",\n",
    "        description=\"Handles simple greetings and hellos using the 'say_hello' tool.\", # Crucial for delegation\n",
    "        tools=[say_hello],\n",
    "    )\n",
    "    print(f\"✅ Agent '{greeting_agent.name}' created using model '{greeting_agent.model}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Could not create Greeting agent. Check API Key ({greeting_agent.model}). Error: {e}\")\n",
    "\n",
    "# --- Farewell Agent ---\n",
    "farewell_agent = None\n",
    "try:\n",
    "    farewell_agent = Agent(\n",
    "        # Can use the same or a different model\n",
    "        model = MODEL_GEMINI_2_0_FLASH,\n",
    "        # model=LiteLlm(model=MODEL_GPT_4O), # If you would like to experiment with other models\n",
    "        name=\"farewell_agent\",\n",
    "        instruction=\"You are the Farewell Agent. Your ONLY task is to provide a polite goodbye message. \"\n",
    "                    \"Use the 'say_goodbye' tool when the user indicates they are leaving or ending the conversation \"\n",
    "                    \"(e.g., using words like 'bye', 'goodbye', 'thanks bye', 'see you'). \"\n",
    "                    \"Do not perform any other actions.\",\n",
    "        description=\"Handles simple farewells and goodbyes using the 'say_goodbye' tool.\", # Crucial for delegation\n",
    "        tools=[say_goodbye],\n",
    "    )\n",
    "    print(f\"✅ Agent '{farewell_agent.name}' created using model '{farewell_agent.model}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Could not create Farewell agent. Check API Key ({farewell_agent.model}). Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7bf1a1",
   "metadata": {},
   "source": [
    "### 3.3 Define the Root Agent (Weather Agent v2) with Sub-Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc8e18a",
   "metadata": {},
   "source": [
    "Now, we upgrade our weather_agent. The key changes are:\n",
    "\n",
    "- Adding the `sub_agents` parameter: We pass a list containing the `greeting_agent` and `farewell_agent` instances we just created.\n",
    "- Updating the `instruction`: We explicitly tell the root agent about its sub-agents and when it should delegate tasks to them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a70e66",
   "metadata": {},
   "source": [
    "**Key Concept: Automatic Delegation (Auto Flow)**\n",
    "\n",
    "By providing the `sub_agents` list, ADK enables automatic delegation. When the root agent receives a user query, its LLM considers not only its own instructions and tools but also the `description` of each sub-agent. If the LLM determines that a query aligns better with a sub-agent's described capability (e.g., \"Handles simple greetings\"), it will automatically generate a special internal action to transfer control to that sub-agent for that turn. The sub-agent then processes the query using its own model, instructions, and tools.\n",
    "\n",
    "**Best Practice:** Ensure the root agent's has clear instruction guide for its delegation decisions. Mention the sub-agents by name and describe the conditions under which delegation should occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d7c45af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Root Agent 'weather_agent_v2' created using model 'gemini-2.0-flash' with sub-agents: ['greeting_agent', 'farewell_agent']\n"
     ]
    }
   ],
   "source": [
    "# @title Define the Root Agent with Sub-Agents\n",
    "\n",
    "# Ensure sub-agents were created successfully before defining the root agent.\n",
    "# Also ensure the original 'get_weather' tool is defined.\n",
    "root_agent = None\n",
    "runner_root = None # Initialize runner\n",
    "\n",
    "if greeting_agent and farewell_agent and 'get_weather' in globals():\n",
    "    # Let's use a capable Gemini model for the root agent to handle orchestration\n",
    "    root_agent_model = MODEL_GEMINI_2_0_FLASH\n",
    "\n",
    "    weather_agent_team = Agent(\n",
    "        name=\"weather_agent_v2\", # Give it a new version name\n",
    "        model=root_agent_model,\n",
    "        description=\"The main coordinator agent. Handles weather requests and delegates greetings/farewells to specialists.\",\n",
    "        instruction=\"You are the main Weather Agent coordinating a team. Your primary responsibility is to provide weather information. \"\n",
    "                    \"Use the 'get_weather' tool ONLY for specific weather requests (e.g., 'weather in London'). \"\n",
    "                    \"You have specialized sub-agents: \"\n",
    "                    \"1. 'greeting_agent': Handles simple greetings like 'Hi', 'Hello'. Delegate to it for these. \"\n",
    "                    \"2. 'farewell_agent': Handles simple farewells like 'Bye', 'See you'. Delegate to it for these. \"\n",
    "                    \"Analyze the user's query. If it's a greeting, delegate to 'greeting_agent'. If it's a farewell, delegate to 'farewell_agent'. \"\n",
    "                    \"If it's a weather request, handle it yourself using 'get_weather'. \"\n",
    "                    \"For anything else, respond appropriately or state you cannot handle it.\",\n",
    "        tools=[get_weather], # Root agent still needs the weather tool for its core task\n",
    "        # Key change: Link the sub-agents here!\n",
    "        sub_agents=[greeting_agent, farewell_agent]\n",
    "    )\n",
    "    print(f\"✅ Root Agent '{weather_agent_team.name}' created using model '{root_agent_model}' with sub-agents: {[sa.name for sa in weather_agent_team.sub_agents]}\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Cannot create root agent because one or more sub-agents failed to initialize or 'get_weather' tool is missing.\")\n",
    "    if not greeting_agent: print(\" - Greeting Agent is missing.\")\n",
    "    if not farewell_agent: print(\" - Farewell Agent is missing.\")\n",
    "    if 'get_weather' not in globals(): print(\" - get_weather function is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5a9b42",
   "metadata": {},
   "source": [
    "## 3.4 Interact with the Agent Team"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638efa41",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc7d3d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting execution using 'await' (default for notebooks)...\n",
      "\n",
      "--- Testing Agent Team Delegation ---\n",
      "Session created: App='weather_tutorial_agent_team', User='user_1_agent_team', Session='session_001_agent_team'\n",
      "Runner created for agent 'weather_agent_v2'.\n",
      "\n",
      ">>> User Query: Hello there!\n",
      "--- Tool: say_hello called with name: None ---\n",
      "<<< Agent Response: Hello, None!\n",
      "\n",
      "\n",
      ">>> User Query: What is the weather in New York?\n",
      "--- Tool: get_weather called for city: New York ---\n",
      "<<< Agent Response: The weather in New York is sunny with a temperature of 25°C.\n",
      "\n",
      "\n",
      ">>> User Query: Thanks, bye!\n",
      "--- Tool: say_goodbye called ---\n",
      "<<< Agent Response: Goodbye! Have a great day.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Interact with the Agent Team\n",
    "import asyncio # Ensure asyncio is imported\n",
    "\n",
    "# Ensure the root agent (e.g., 'weather_agent_team' or 'root_agent' from the previous cell) is defined.\n",
    "# Ensure the call_agent_async function is defined.\n",
    "\n",
    "# Check if the root agent variable exists before defining the conversation function\n",
    "root_agent_var_name = 'root_agent' # Default name from Step 3 guide\n",
    "if 'weather_agent_team' in globals(): # Check if user used this name instead\n",
    "    root_agent_var_name = 'weather_agent_team'\n",
    "elif 'root_agent' not in globals():\n",
    "    print(\"⚠️ Root agent ('root_agent' or 'weather_agent_team') not found. Cannot define run_team_conversation.\")\n",
    "    # Assign a dummy value to prevent NameError later if the code block runs anyway\n",
    "    root_agent = None # Or set a flag to prevent execution\n",
    "\n",
    "# Only define and run if the root agent exists\n",
    "if root_agent_var_name in globals() and globals()[root_agent_var_name]:\n",
    "    # Define the main async function for the conversation logic.\n",
    "    # The 'await' keywords INSIDE this function are necessary for async operations.\n",
    "    async def run_team_conversation():\n",
    "        print(\"\\n--- Testing Agent Team Delegation ---\")\n",
    "        session_service = InMemorySessionService()\n",
    "        APP_NAME = \"weather_tutorial_agent_team\"\n",
    "        USER_ID = \"user_1_agent_team\"\n",
    "        SESSION_ID = \"session_001_agent_team\"\n",
    "        session = session_service.create_session(\n",
    "            app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID\n",
    "        )\n",
    "        print(f\"Session created: App='{APP_NAME}', User='{USER_ID}', Session='{SESSION_ID}'\")\n",
    "\n",
    "        actual_root_agent = globals()[root_agent_var_name]\n",
    "        runner_agent_team = Runner( # Or use InMemoryRunner\n",
    "            agent=actual_root_agent,\n",
    "            app_name=APP_NAME,\n",
    "            session_service=session_service\n",
    "        )\n",
    "        print(f\"Runner created for agent '{actual_root_agent.name}'.\")\n",
    "\n",
    "        # --- Interactions using await (correct within async def) ---\n",
    "        await call_agent_async(query = \"Hello there!\",\n",
    "                               runner=runner_agent_team,\n",
    "                               user_id=USER_ID,\n",
    "                               session_id=SESSION_ID)\n",
    "        await call_agent_async(query = \"What is the weather in New York?\",\n",
    "                               runner=runner_agent_team,\n",
    "                               user_id=USER_ID,\n",
    "                               session_id=SESSION_ID)\n",
    "        await call_agent_async(query = \"Thanks, bye!\",\n",
    "                               runner=runner_agent_team,\n",
    "                               user_id=USER_ID,\n",
    "                               session_id=SESSION_ID)\n",
    "\n",
    "    # --- Execute the `run_team_conversation` async function ---\n",
    "    # Choose ONE of the methods below based on your environment.\n",
    "    # Note: This may require API keys for the models used!\n",
    "\n",
    "    # METHOD 1: Direct await (Default for Notebooks/Async REPLs)\n",
    "    # If your environment supports top-level await (like Colab/Jupyter notebooks),\n",
    "    # it means an event loop is already running, so you can directly await the function.\n",
    "    print(\"Attempting execution using 'await' (default for notebooks)...\")\n",
    "    await run_team_conversation()\n",
    "\n",
    "    # METHOD 2: asyncio.run (For Standard Python Scripts [.py])\n",
    "    # If running this code as a standard Python script from your terminal,\n",
    "    # the script context is synchronous. `asyncio.run()` is needed to\n",
    "    # create and manage an event loop to execute your async function.\n",
    "    # To use this method:\n",
    "    # 1. Comment out the `await run_team_conversation()` line above.\n",
    "    # 2. Uncomment the following block:\n",
    "    \"\"\"\n",
    "    import asyncio\n",
    "    if __name__ == \"__main__\": # Ensures this runs only when script is executed directly\n",
    "        print(\"Executing using 'asyncio.run()' (for standard Python scripts)...\")\n",
    "        try:\n",
    "            # This creates an event loop, runs your async function, and closes the loop.\n",
    "            asyncio.run(run_team_conversation())\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "    \"\"\"\n",
    "\n",
    "else:\n",
    "    # This message prints if the root agent variable wasn't found earlier\n",
    "    print(\"\\n⚠️ Skipping agent team conversation execution as the root agent was not successfully defined in a previous step.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93f498d",
   "metadata": {},
   "source": [
    "## 4. Adding Memory and Personalization with Session State"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d2c411",
   "metadata": {},
   "source": [
    "To create more sophisticated and context-aware experiences, agents need memory. ADK provides this through Session State.\n",
    "\n",
    "**What is Session State?**\n",
    "\n",
    "- It's a Python dictionary (session.state) tied to a specific user session (identified by APP_NAME, USER_ID, SESSION_ID).\n",
    "- It persists information across multiple conversational turns within that session.\n",
    "- Agents and Tools can read from and write to this state, allowing them to remember details, adapt behavior, and personalize responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685c17bc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
