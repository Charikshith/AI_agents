{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio,os\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.models.openai import OpenAIModel\n",
    "from pydantic_ai.providers.openai import OpenAIProvider\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"D:\\\\Code\\\\AI\\\\.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "def to_markdown(data, indent=0):\n",
    "    markdown = \"\"\n",
    "    if isinstance(data, BaseModel):\n",
    "        data = data.model_dump()\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            markdown += f\"{'#' * (indent + 2)} {key.upper()}\\n\"\n",
    "            if isinstance(value, (dict, list, BaseModel)):\n",
    "                markdown += to_markdown(value, indent + 1)\n",
    "            else:\n",
    "                markdown += f\"{value}\\n\\n\"\n",
    "    elif isinstance(data, list):\n",
    "        for item in data:\n",
    "            if isinstance(item, (dict, list, BaseModel)):\n",
    "                markdown += to_markdown(item, indent)\n",
    "            else:\n",
    "                markdown += f\"- {item}\\n\"\n",
    "        markdown += \"\\n\"\n",
    "    else:\n",
    "        markdown += f\"{data}\\n\\n\"\n",
    "    return markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Class Components\n",
    "\n",
    "The Agent class can be thought of as a container for the following components, which define its behavior and capabilities:\n",
    "\n",
    "| Component                   | Description                                                                                                                                                                  |\n",
    "| --------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **System Prompt(s)**        | A set of instructions, crafted by the developer, that guide the Large Language Model (LLM) in its operation.                                                              |\n",
    "| **Function Tool(s)**       | Functions that the LLM has the ability to invoke during response generation. These tools provide the LLM with external information or capabilities.                                             |\n",
    "| **Structured Result Type** | The specific data type the LLM is required to return as the final output of its run, if one is defined.                                                                            |\n",
    "| **Dependency Type Constraint** | Defines the dependencies that can be used by System prompts functions, tools, and result validators when they are executed.                                                                         |\n",
    "| **LLM Model**               | An optional default Large Language Model (LLM) associated with the agent.  A different model can also be specified when the agent is run.                         |\n",
    "| **Model Settings**          | Optional default configuration parameters used to fine-tune the behavior of the model requests. These can be overridden when running the agent. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example demonstrates the basic usage of PydanticAI agents.\n",
    "Key concepts:\n",
    "- Creating a basic agent with a system prompt\n",
    "- Running synchronous queries\n",
    "- Accessing response data, message history, and costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Simple Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of the Pandavas, the legendary heroes of the Indian epic Mahabharata, was **Indraprastha**. According to the epic, the city was established by the Pandavas after they were granted a barren land by their cousins, the Kauravas. With the help of Lord Krishna and the divine architect Vishwakarma, they transformed the land into a magnificent city, which became their capital. Indraprastha is often identified with modern-day Delhi, India.\n",
      "[ModelRequest(parts=[SystemPromptPart(content=' You are a helpful assistant.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='What is the capital of the Pandavas?', timestamp=datetime.datetime(2025, 3, 16, 15, 50, 58, 392552, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='The capital of the Pandavas, the legendary heroes of the Indian epic Mahabharata, was **Indraprastha**. According to the epic, the city was established by the Pandavas after they were granted a barren land by their cousins, the Kauravas. With the help of Lord Krishna and the divine architect Vishwakarma, they transformed the land into a magnificent city, which became their capital. Indraprastha is often identified with modern-day Delhi, India.', part_kind='text')], model_name='deepseek-chat', timestamp=datetime.datetime(2025, 3, 16, 15, 50, 58, tzinfo=datetime.timezone.utc), kind='response')]\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# 1. Simple Agent - Hello World Example\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "\n",
    "deepseek_model = OpenAIModel(\n",
    "    model_name='deepseek-chat',\n",
    "    provider=OpenAIProvider(base_url='https://api.deepseek.com/',\n",
    "                            api_key=os.getenv(\"DEEPSEEK_API_KEY\"))\n",
    "    )\n",
    "\n",
    "agent = Agent(model=deepseek_model,system_prompt=\" You are a helpful assistant.\")\n",
    "\n",
    "response=agent.run_sync(\"What is the capital of the Pandavas?\")\n",
    "\n",
    "print(response.data)\n",
    "print(response.all_messages())\n",
    "# print(response.cost()) #AttributeError: 'AgentRunResult' object has no attribute 'cost'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your two previous questions were:\n",
      "\n",
      "1. **\"What is the capital of the Pandavas?\"**\n",
      "2. **\"What was my 2 previous question?\"**\n"
     ]
    }
   ],
   "source": [
    "response2 = agent.run_sync(user_prompt=\"What was my 2 previous question? \",\n",
    "                           message_history=response.new_messages(),)\n",
    "print(response2.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Agent with Structured Response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows how to get structured, type-safe responses from the agent.\n",
    "Key concepts:\n",
    "- Using Pydantic models to define response structure\n",
    "- Type validation and safety\n",
    "- Field descriptions for better model understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"response\": \"To track your order #12345, please visit our website and go to the 'Order Tracking' section. Enter your order number and the email address used for the purchase. You will receive real-time updates on the status of your order. If you encounter any issues, feel free to contact our support team.\",\n",
      "  \"needs_escalation\": false,\n",
      "  \"follow_up_required\": false,\n",
      "  \"sentiment\": \"neutral\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# 2. Agent with Structured Response\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "from pydantic import BaseModel,Field\n",
    "\n",
    "class GetResponse(BaseModel):\n",
    "    \"\"\" Structured Response with metadata\"\"\"\n",
    "    response: str\n",
    "    needs_escalation: bool\n",
    "    follow_up_required: bool\n",
    "    sentiment: str = Field(description=\"Customer sentiment analysis\")\n",
    "\n",
    "# Model is configure above\n",
    "agent2=Agent(model=deepseek_model,system_prompt=\"\"\" You are a intelligent customer support agent. Analyze queries carefully and provide structured response\"\"\",\n",
    "             result_type=GetResponse)\n",
    "\n",
    "response = agent2.run_sync(\" How can I track my order #12345\")\n",
    "print(response.data.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Agent with Structured Response & Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example demonstrates how to use dependencies and context in agents.\n",
    "Key concepts:\n",
    "- Defining complex data models with Pydantic\n",
    "- Injecting runtime dependencies\n",
    "- Using dynamic system prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List,Optional\n",
    "from pydantic_ai import Agent,ModelRetry,RunContext,Tool\n",
    "\n",
    "\n",
    "# Define order schema\n",
    "class Order(BaseModel):\n",
    "    \"\"\" Structure for order details\"\"\"\n",
    "    order_id: str\n",
    "    status: str\n",
    "    items : List[str]\n",
    "\n",
    "# Define Customer schema\n",
    "class CustomerDetails(BaseModel):\n",
    "    \"\"\"Structure for incoming customer queries\"\"\"\n",
    "    customer_id: str\n",
    "    name: str\n",
    "    email: str\n",
    "    orders: Optional[List[Order]] =None\n",
    "\n",
    "class GetResponse(BaseModel):\n",
    "    \"\"\" Structured Response with metadata\"\"\"\n",
    "    response: str\n",
    "    needs_escalation: bool\n",
    "    follow_up_required: bool\n",
    "    sentiment: str = Field(description=\"Customer sentiment analysis\")\n",
    "\n",
    "# Agent with structured output and dependencies\n",
    "\n",
    "support_agent= Agent(model=deepseek_model,\n",
    "                     result_type=GetResponse,\n",
    "                     deps_type=CustomerDetails,\n",
    "                     retries=3,\n",
    "                     system_prompt=\"\"\" You are an intelligent customer support agent.\n",
    "                                    Analyze queries carefully and provide structured response.\n",
    "                                    Always greet the customer and provide a helpful response.\"\"\")\n",
    "\n",
    "# Add dynamic system prompt based on dependencies\n",
    "@support_agent.system_prompt\n",
    "async def add_customer_name(ctx: RunContext[CustomerDetails])-> str:\n",
    "    return f\"Customer details: {to_markdown(ctx.deps)}\" # These depend in some way on the context that is'nt know until runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"response\": \"You ordered the following items: Blue Jeans and T-Shirt.\",\n",
      "  \"needs_escalation\": false,\n",
      "  \"follow_up_required\": false,\n",
      "  \"sentiment\": \"neutral\"\n",
      "}\n",
      "Customer Details:\n",
      "Name: John Doe\n",
      "Email: john.doe@example.com\n",
      "\n",
      "Response Details:\n",
      "You ordered the following items: Blue Jeans and T-Shirt.\n",
      "\n",
      "Status:\n",
      "Follow-up Required: False\n",
      "Needs Escalation: False\n"
     ]
    }
   ],
   "source": [
    "customer = CustomerDetails(\n",
    "    customer_id=\"1\",\n",
    "    # customer_id=1,\n",
    "    name=\"John Doe\",\n",
    "    email=\"john.doe@example.com\",\n",
    "    orders=[\n",
    "        Order(order_id=\"12345\", status=\"shipped\", items=[\"Blue Jeans\", \"T-Shirt\"]),\n",
    "    ],\n",
    ")\n",
    "\n",
    "response = support_agent.run_sync(user_prompt=\"What did I order?\", deps=customer)\n",
    "\n",
    "response.all_messages()\n",
    "print(response.data.model_dump_json(indent=2))\n",
    "\n",
    "print(\n",
    "    \"Customer Details:\\n\"\n",
    "    f\"Name: {customer.name}\\n\"\n",
    "    f\"Email: {customer.email}\\n\\n\"\n",
    "    \"Response Details:\\n\"\n",
    "    f\"{response.data.response}\\n\\n\"\n",
    "    \"Status:\\n\"\n",
    "    f\"Follow-up Required: {response.data.follow_up_required}\\n\"\n",
    "    f\"Needs Escalation: {response.data.needs_escalation}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
